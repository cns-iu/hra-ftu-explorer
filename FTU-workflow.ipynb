{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213248b9",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "Figma diagram: https://www.figma.com/file/PFKdJO3HTIcM9g4nmVONCT/HRA-Data-Explorer?type=whiteboard&node-id=1%3A108&t=XGoN91s7IKbyZ7xk-1\n",
    "\n",
    "Below is the information about the diagram:\n",
    "\n",
    "1. Dataset Collections:\n",
    "The process begins with RUI Registered Tissue datasets, a collection of tissue datasets registered in a specific repository or database.\n",
    "These datasets are linked to specific Organs and Anatomical Structures.\n",
    "\n",
    "2. Dataset Processing:\n",
    "The datasets are processed to produce Anatomical Structures/Cell type information of 2D FTUs.\n",
    "There is a decision point or a step to possibly sort these structures, which leads to the extraction of a Cell Summary, including cell type biomarker gene expression data.\n",
    "    \n",
    "    1. Compare FTU's cell type information between Azimuth, PopV and Celltypist\n",
    "    2. Get the list of dataset for FTU.\n",
    "        1. Cell summary from the atlas-as-cell-summaries.jsonld\n",
    "        2. add organ data from the cell annotation crosswalk files\n",
    "    3. Any dataset that is been shared among two FTUs\n",
    "\n",
    "3. Cell Type Mapping:\n",
    "list of 2D FTUs are used to map Cell Types, leading to a set of inquiries on how to best extract data from the datasets used in Step 1 and 2\n",
    "\n",
    "4. Vasculature Mapping\n",
    "\n",
    "5. Share cell type info:\n",
    "    The following cell types from your dataset are commonly known to be present both within FTUs and around them:\n",
    "\n",
    "        1. Endothelial Cells:\n",
    "\n",
    "        glomerular capillary endothelial cell\n",
    "        efferent arteriole endothelial cell\n",
    "        afferent arteriole endothelial cell\n",
    "        peritubular capillary endothelial cell\n",
    "        alveolar capillary type 1 endothelial cell\n",
    "        capillary endothelial cell\n",
    "        endothelial cell\n",
    "        endothelial cell of artery\n",
    "        vein endothelial cell\n",
    "        endothelial cell of hepatic sinusoid\n",
    "        blood vessel endothelial cell\n",
    "        splenic endothelial cell\n",
    "        \n",
    "        2. Fibroblasts and Myofibroblasts:\n",
    "\n",
    "        alveolar type 1 fibroblast\n",
    "        secondary crest myofibroblasts\n",
    "        skin fibroblast\n",
    "        hepatic portal fibroblast\n",
    "        fibroblast of subepithelial connective tissue of prostatic gland\n",
    "        fibroblast of connective tissue of prostate\n",
    "        fibroblast\n",
    "        myofibroblast\n",
    "        \n",
    "        3. Macrophages and Dendritic Cells:\n",
    "\n",
    "        macrophage\n",
    "        thymic plasmacytoid dendritic cell\n",
    "        thymic cortical macrophage\n",
    "        thymic medullary macrophage\n",
    "        follicular dendritic cell\n",
    "        splenic tingible body macrophage\n",
    "        splenic marginal zone macrophage\n",
    "        splenic red pulp macrophage\n",
    "        dendritic cell, human\n",
    "        splenic white pulp macrophage\n",
    "        dendritic cell\n",
    "        \n",
    "        4. Stem/Progenitor Cells:\n",
    "\n",
    "        intestinal crypt stem cell of large intestine\n",
    "        hepatic progenitor cell\n",
    "        hematopoetic stem cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a5dc6",
   "metadata": {},
   "source": [
    "### Load Reference files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b567d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths to save the downloaded files\n",
    "popv_local_path = 'ref_data/popv.csv'\n",
    "celltypist_local_path = 'ref_data/celltypist.csv'\n",
    "azimuth_local_path = 'ref_data/azimuth.csv'\n",
    "ftu_cell_count_path = 'ref_data/FTU Cell Count Table - Cell_Type_Count.csv'\n",
    "\n",
    "# Load the files\n",
    "popv = pd.read_csv(popv_local_path)\n",
    "celltypist = pd.read_csv(celltypist_local_path)\n",
    "azimuth = pd.read_csv(azimuth_local_path)\n",
    "ftu_cell_count = pd.read_csv(ftu_cell_count_path)\n",
    "\n",
    "# Load the JSON file\n",
    "atlas_enriched_dataset_graph_path = 'ref_data/atlas-enriched-dataset-graph.jsonld'\n",
    "atlas_as_cell_summaries_path = 'ref_data/atlas-as-cell-summaries.jsonld'\n",
    "\n",
    "with open(atlas_as_cell_summaries_path, 'r') as file:\n",
    "    json_data_summary = json.load(file)\n",
    "\n",
    "with open(atlas_enriched_dataset_graph_path, 'r') as file:\n",
    "    json_data_enriched = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c450b3",
   "metadata": {},
   "source": [
    "### Get the Cell annotation tool information for cell types in FTUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "organ_to_uberon = {\n",
    "    'Kidney': 'UBERON:0002113',\n",
    "    'Lung': 'UBERON:0002048',\n",
    "    'Pancreas': 'UBERON:0001264',\n",
    "    'Large Intestine': 'UBERON:0002107',\n",
    "    'Skin': 'UBERON:0002097',\n",
    "    'Liver': 'UBERON:0002108',\n",
    "    'Prostate': 'UBERON:0002367',\n",
    "    'Thymus': 'UBERON:0002371',\n",
    "    'Spleen': 'UBERON:0002370',\n",
    "    'Small Intestine': 'UBERON:0002106'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftu_cell_count = ftu_cell_count.drop(columns=['Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9','Unnamed: 10','Unnamed: 11','Unnamed: 12','Unnamed: 13','Unnamed: 14'], axis = False)\n",
    "\n",
    "# Rename 'CT ID in CL' to 'CL_ID' for consistency\n",
    "ftu_cell_count = ftu_cell_count.rename(columns={'CT ID in CL': 'CL_ID'})\n",
    "ftu_cell_count = ftu_cell_count.rename(columns={'CT Label in CL': 'CL_Label_FTU'})\n",
    "\n",
    "# Filter FTU cell count to include only rows where `CT ID in CL` contains `CL`\n",
    "ftu_cell_count_filtered = ftu_cell_count[ftu_cell_count['CL_ID'].str.contains('CL', na=False)]\n",
    "\n",
    "# Select necessary columns from ftu_cell_count\n",
    "ftu_cell_count_filtered = ftu_cell_count_filtered[['Organ', 'FTU Label in Uberon', 'FTU ID in Uberon', 'CL_ID', 'CL_Label_FTU']]\n",
    "\n",
    "# Merge the dataframes based on 'CL_ID'\n",
    "merged_df = ftu_cell_count_filtered.merge(azimuth[['CL_ID', 'CL_Label']], on='CL_ID', how='left', suffixes=('', '_azimuth'))\n",
    "merged_df = merged_df.rename(columns={'CL_Label': 'CL_Label_azimuth'})\n",
    "\n",
    "merged_df = merged_df.merge(celltypist[['CL_ID', 'CL_Label']], on='CL_ID', how='left', suffixes=('', '_celltypist'))\n",
    "merged_df = merged_df.rename(columns={'CL_Label': 'CL_Label_celltypist'})\n",
    "\n",
    "merged_df = merged_df.merge(popv[['CL_ID', 'CL_Label']], on='CL_ID', how='left', suffixes=('', '_popv'))\n",
    "merged_df = merged_df.rename(columns={'CL_Label': 'CL_Label_popv'})\n",
    "\n",
    "# Populating the columns azimuth, celltypist, popv with 1 if there is a match, otherwise 0\n",
    "merged_df['azimuth'] = merged_df['CL_Label_azimuth'].notna().astype(int)\n",
    "merged_df['celltypist'] = merged_df['CL_Label_celltypist'].notna().astype(int)\n",
    "merged_df['popv'] = merged_df['CL_Label_popv'].notna().astype(int)\n",
    "\n",
    "# Renaming 'CT Label in CL' to 'CT Label'\n",
    "merged_df = merged_df.rename(columns={'CL_Label_FTU': 'CT Label'})\n",
    "\n",
    "# Selecting columns for final output\n",
    "final_columns = ['Organ', 'FTU Label in Uberon', 'FTU ID in Uberon', 'CL_ID', 'CT Label', 'azimuth', 'celltypist', 'popv']\n",
    "ftu_ct_ann_info_df = merged_df[final_columns]\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "output_path = 'output/FTU-CT-AnnTool-info.csv'\n",
    "ftu_ct_ann_info_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first few rows of the final dataframe\n",
    "print(ftu_ct_ann_info_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the organ names in FTU cell count table to UBERON IDs\n",
    "ftu_cell_count_filtered.loc[:, 'Organ_ID'] = ftu_cell_count_filtered['Organ'].map(organ_to_uberon)\n",
    "\n",
    "# Prepare a common structure to hold the results\n",
    "result = []\n",
    "\n",
    "# Function to dynamically generate match info for celltypist and azimuth\n",
    "def generate_match_info(tool_name, tool_data):\n",
    "    levels = set()\n",
    "    for organ_level in tool_data['Organ_Level']:\n",
    "        if 'level' in organ_level.lower():\n",
    "            level = organ_level.split('_')[-2]\n",
    "        else:\n",
    "            level = organ_level.split('_')[-1]\n",
    "        levels.add(level)\n",
    "    \n",
    "    match_info = {f'{tool_name}_{level}': 0 for level in levels}\n",
    "    return match_info, levels\n",
    "\n",
    "\n",
    "# Dynamically generate the match info for celltypist and azimuth\n",
    "celltypist_info, celltypist_levels = generate_match_info('celltypist', celltypist)\n",
    "azimuth_info, azimuth_levels = generate_match_info('azimuth', azimuth)\n",
    "\n",
    "# Iterate over the filtered FTU cell count data\n",
    "for idx, ftu_row in ftu_cell_count_filtered.iterrows():\n",
    "    organ = ftu_row['Organ_ID']\n",
    "    ftu_label = ftu_row['FTU Label in Uberon']\n",
    "    ftu_id = ftu_row['FTU ID in Uberon']\n",
    "    cl_id = ftu_row['CL_ID']\n",
    "    cl_label = ftu_row['CL_Label_FTU']\n",
    "    \n",
    "    # Initialize match columns\n",
    "    match_info = {\n",
    "        'Organ': ftu_row['Organ'],\n",
    "        'FTU Label in Uberon': ftu_label,\n",
    "        'FTU ID in Uberon': ftu_id,\n",
    "        'CL_ID': cl_id,\n",
    "        'CL_Label_FTU': cl_label,\n",
    "        'popv': 0\n",
    "    }\n",
    "    match_info.update({key: 0 for key in celltypist_info.keys()})\n",
    "    match_info.update({key: 0 for key in azimuth_info.keys()})\n",
    "    \n",
    "    # Check in celltypist\n",
    "    celltypist_matches = celltypist[(celltypist['CL_ID'] == cl_id) & (celltypist['Organ_ID'] == organ)]\n",
    "    for _, ct_match in celltypist_matches.iterrows():\n",
    "        if 'level' in ct_match['Organ_Level'].lower():\n",
    "            level = ct_match['Organ_Level'].split('_')[-2]  # Extract the level number\n",
    "        else:\n",
    "            level = ct_match['Organ_Level'].split('_')[-1]  # Extract the level number\n",
    "        match_info[f'celltypist_{level}'] = 1\n",
    "\n",
    "    # Check in azimuth\n",
    "    azimuth_matches = azimuth[(azimuth['CL_ID'] == cl_id) & (azimuth['Organ_ID'] == organ)]\n",
    "    for _, az_match in azimuth_matches.iterrows():\n",
    "        if 'level' in az_match['Organ_Level'].lower():\n",
    "            level = az_match['Organ_Level'].split('_')[-2]  # Extract the level number\n",
    "        else:\n",
    "            level = az_match['Organ_Level'].split('_')[-1]  # Extract the level number\n",
    "        match_info[f'azimuth_{level}'] = 1\n",
    "\n",
    "    # Check in popv\n",
    "    popv_matches = popv[(popv['CL_ID'] == cl_id) & (popv['Organ_ID'] == organ)]\n",
    "    if not popv_matches.empty:\n",
    "        match_info['popv'] = 1\n",
    "\n",
    "    # Append to results\n",
    "    result.append(match_info)\n",
    "\n",
    "# Create a dataframe from the results\n",
    "result_df = pd.DataFrame(result)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e954cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to a CSV file\n",
    "output_path = 'output/FTU-CT-AnnTool-level-info.csv'\n",
    "result_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"File saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75444f91",
   "metadata": {},
   "source": [
    "### Retrieve the dataset information pertaining to FTU cell types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30015c",
   "metadata": {},
   "source": [
    "#### Understanding the structure, content, and formatting of the JSON files namely, atlas-as-cell-summaries.jsonld and atlas-enriched-dataset-graph.jsonld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dec1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract structure and keys of the JSON\n",
    "def extract_structure(data, level=0):\n",
    "    structure = {}\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            structure[key] = extract_structure(value, level + 1)\n",
    "    elif isinstance(data, list) and len(data) > 0:\n",
    "        structure = [extract_structure(data[0], level + 1)]\n",
    "    else:\n",
    "        structure = None\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fac17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structure\n",
    "json_structure_cell_summaries = extract_structure(json_data_summary)\n",
    "json_structure_cell_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structure\n",
    "json_structure_enriched_dataset_graph = extract_structure(json_data_enriched)\n",
    "json_structure_enriched_dataset_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e19574",
   "metadata": {},
   "source": [
    "#### Extract Source, CT and dataset information from as-cell-summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e91c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant data from the JSON file\n",
    "json_graph = json_data_summary['@graph']\n",
    "\n",
    "# Convert the JSON graph to a DataFrame for easier manipulation\n",
    "json_df = pd.json_normalize(json_graph)\n",
    "\n",
    "# Ensure modality is expanded correctly\n",
    "expanded_json_df = json_df.explode('summary').reset_index(drop=True)\n",
    "expanded_json_df['modality'] = json_df.explode('modality').reset_index(drop=True)['modality']\n",
    "\n",
    "# Normalize the summary column and merge with expanded_json_df\n",
    "summary_df = pd.json_normalize(expanded_json_df['summary'])\n",
    "merged_json_df = pd.concat([expanded_json_df.drop(columns=['summary']), summary_df], axis=1)\n",
    "\n",
    "# Ensure correct modality assignment\n",
    "merged_json_df['modality'] = merged_json_df['modality'].fillna(method='ffill')\n",
    "\n",
    "# Extract relevant columns from the CSV data\n",
    "ftu_relevant_columns = ftu_cell_count[['Organ', 'FTU Label in Uberon', 'FTU ID in Uberon','CL_ID', 'CL_Label_FTU']]\n",
    "\n",
    "# Merge the CSV and JSON DataFrames based on matching cell_id\n",
    "merged_data = pd.merge(\n",
    "    merged_json_df,\n",
    "    ftu_relevant_columns,\n",
    "    left_on='cell_id',\n",
    "    right_on='CL_ID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Create the final DataFrame with the desired columns\n",
    "CTs_with_datasets_df = merged_data[[\n",
    "    'cell_id',\n",
    "    'cell_label',\n",
    "    'annotation_method',\n",
    "    'modality',\n",
    "    'cell_source_label',\n",
    "    'sex',\n",
    "    'aggregated_summaries'\n",
    "]]\n",
    "\n",
    "# Rename the columns as specified\n",
    "CTs_with_datasets_df.columns = [\n",
    "    'cell_id',\n",
    "    'cell_label',\n",
    "    'annotation_method',\n",
    "    'modality',\n",
    "    'cell_source_label',\n",
    "    'sex',\n",
    "    'datasets'\n",
    "]\n",
    "\n",
    "# Add the new column \"#datasets\"\n",
    "CTs_with_datasets_df['#datasets'] = CTs_with_datasets_df['datasets'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Check for null values in the 'modality' column again\n",
    "null_modality_entries_after_correction = CTs_with_datasets_df[CTs_with_datasets_df['modality'].isnull()]\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(CTs_with_datasets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0917d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "final_csv_path = 'output/CTs-with-datasets-info.csv'\n",
    "CTs_with_datasets_df.to_csv(final_csv_path, index=False)\n",
    "print(f\"Final CSV saved to: {final_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTs_with_datasets_df['modality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f1e97",
   "metadata": {},
   "source": [
    "#### Extract gene information for idenfied CT - dataset combination from enriched-dataset-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe with the specified columns\n",
    "columns = [\n",
    "    'organ_id', 'organ_name', 'reference_organ', 'cell_id', 'cell_label', 'annotation_method', \n",
    "    'cell_source_label', 'as_label', 'sex', 'aggregated_summaries', 'gene_id', \n",
    "    'gene_label', 'ensembl_id', 'mean_gene_expr_value'\n",
    "]\n",
    "result_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Function to extract and match data based on cell_id and annotation_method\n",
    "def extract_data(csv_row, json_data):\n",
    "    matches = []\n",
    "    cell_id = csv_row['cell_id']\n",
    "    annotation_method = csv_row['annotation_method']\n",
    "    aggregated_summaries = csv_row['datasets']  # convert string representation of list to actual list\n",
    "    organ_name = 'unknown'\n",
    "    for entry in json_data[\"@graph\"]:\n",
    "        for sample in entry.get('samples', []):\n",
    "            rui_location = sample.get('rui_location', {})\n",
    "            all_collisions = rui_location.get('all_collisions', [])\n",
    "            for collision in all_collisions:\n",
    "                collisions = collision.get('collisions', [])\n",
    "                for col in collisions:\n",
    "                    reference_organ = col.get('reference_organ', 'unknown')\n",
    "                    as_label = col.get('as_label', 'unknown')\n",
    "                    for section in sample.get('sections', []):\n",
    "                        for dataset in section.get('datasets', []):\n",
    "                            summaries = dataset.get('summaries', [])\n",
    "                            organ_id = dataset.get('organ_id', 'unknown')\n",
    "                            for summary in summaries:\n",
    "                                if summary.get('annotation_method') == annotation_method:\n",
    "                                    for summ in summary['summary']:\n",
    "                                        if isinstance(summ, dict) and summ['cell_id'] == cell_id:\n",
    "                                            for aggregated_summary in aggregated_summaries:\n",
    "                                                if aggregated_summary in dataset['@id']:\n",
    "                                                    for gene_expr in summ.get('gene_expr', []):\n",
    "                                                        if isinstance(gene_expr, dict):  # Ensure gene_expr is a dictionary\n",
    "                                                            new_row = {\n",
    "                                                                'organ_id': organ_id,\n",
    "                                                                'organ_name': organ_name,\n",
    "                                                                'reference_organ': reference_organ,                                                                \n",
    "                                                                'cell_id': cell_id,\n",
    "                                                                'cell_label': summ['cell_label'],\n",
    "                                                                'annotation_method': annotation_method,\n",
    "                                                                'cell_source_label': csv_row['cell_source_label'],\n",
    "                                                                'as_label': as_label,\n",
    "                                                                'sex': csv_row['sex'],\n",
    "                                                                'dataset': aggregated_summary,\n",
    "                                                                'gene_id': gene_expr.get('gene_id'),\n",
    "                                                                'gene_label': gene_expr.get('gene_label'),\n",
    "                                                                'ensembl_id': gene_expr.get('ensembl_id'),\n",
    "                                                                'mean_gene_expr_value': gene_expr.get('mean_gene_expr_value'),\n",
    "                                                                \n",
    "                                                            }\n",
    "                                                            matches.append(new_row)\n",
    "    return matches\n",
    "\n",
    "# Iterate over the CSV data and extract matched data\n",
    "for index, row in CTs_with_datasets_df.iterrows():\n",
    "    if row['cell_source_label']:  # Filter data by cell_source_label\n",
    "        matches = extract_data(row, json_data_enriched)\n",
    "        if matches:\n",
    "            result_df = pd.concat([result_df, pd.DataFrame(matches)], ignore_index=True)\n",
    "\n",
    "# Display the new dataframe\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique organ IDs\n",
    "result_df[\"organ_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dec88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_id_to_name = {\n",
    "    'http://purl.obolibrary.org/obo/UBERON_0002108' : 'small intestine',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0000059': 'large intestine',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0002113': 'kidney',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0000948': 'heart',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0001255': 'urinary bladder',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0002048': 'lung',\n",
    "'http://purl.obolibrary.org/obo/UBERON_0002107': 'liver'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column to the dataframe\n",
    "result_df['organ_name'] = result_df['organ_id'].map(organ_id_to_name)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0549661",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['organ_name'] == 'urinary bladder'][['cell_label', 'cell_source_label']]['cell_label'].unique()\n",
    "\n",
    "# Corrected query to filter the DataFrame\n",
    "filtered_df_ub = result_df[result_df['organ_name'] == 'urinary bladder']\n",
    "aggregated_summaries = filtered_df_ub['dataset']\n",
    "\n",
    "# Display the aggregated_summaries\n",
    "print(aggregated_summaries.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected query to filter the DataFrame\n",
    "filtered_df = result_df[(result_df['organ_name'] == 'heart') & (result_df['cell_label'] == 'hepatocyte')]\n",
    "aggregated_summaries = filtered_df['dataset']\n",
    "\n",
    "# Display the aggregated_summaries\n",
    "print(aggregated_summaries.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('output/filtered-CTs-with-datasets-with-gene-information-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b46188",
   "metadata": {},
   "source": [
    "##### Sanity check of the organ_id, cell_source_label and cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d587b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['cell_source_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['cell_source_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_labels = set(final_df['cell_source_label'].unique()) - set(result_df['cell_source_label'])\n",
    "print(\"Difference in cell_source_label:\")\n",
    "print(difference_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_ids = set(final_df['cell_id'].unique()) - set(result_df['cell_id'])\n",
    "print(\"Difference in cell_ids:\")\n",
    "print(difference_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique cell_labels in the provided CSV file\n",
    "ftu_cell_labels = set(ftu_cell_count['CL_Label_FTU'].unique())\n",
    "ftu_cell_ids = set(ftu_cell_count['CL_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc073f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_labels_set = set()\n",
    "for label in difference_labels:\n",
    "    cell_labels = final_df[final_df['cell_source_label'] == label]['cell_label']\n",
    "    cell_labels_set.update(cell_labels) \n",
    "    \n",
    "# Check for matches between cell_labels_set and csv_cell_labels\n",
    "matches_label = cell_labels_set.intersection(ftu_cell_labels)\n",
    "matches_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids_set = set()\n",
    "for ids in difference_ids:\n",
    "    cell_ids = final_df[final_df['cell_id'] == ids]['cell_id']\n",
    "    cell_ids_set.update(cell_ids)\n",
    "    \n",
    "matches_id = cell_ids_set.intersection(ftu_cell_ids)\n",
    "matches_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2922ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.DataFrame()\n",
    "for ids in matches_id:\n",
    "    match_df = pd.concat([match_df, (ftu_cell_count[ftu_cell_count['CL_ID'] == ids])],ignore_index=True)\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTs_with_datasets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a7b9b",
   "metadata": {},
   "source": [
    "### Organ and CTann level information as per CTann crosswalk files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique organ levels for each file\n",
    "azimuth_organs = azimuth['Organ_Level'].unique().tolist()\n",
    "celltypist_organs = celltypist['Organ_Level'].unique().tolist()\n",
    "popv_organs = popv['Organ_Level'].unique().tolist()\n",
    "\n",
    "print(\"Azimuth Organs:\", azimuth_organs)\n",
    "print()\n",
    "print(\"Celltypist Organs:\", celltypist_organs)\n",
    "print()\n",
    "print(\"Popv Organs:\", popv_organs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column in final_output_df\n",
    "CTs_with_datasets_df.rename(columns={'cell_id': 'CL_ID'}, inplace=True)\n",
    "\n",
    "# Merge with azimuth_df\n",
    "final_output_azimuth = CTs_with_datasets_df[CTs_with_datasets_df['annotation_method'] == 'azimuth'].merge(\n",
    "    azimuth[['CL_ID', 'Organ_Level']], on='CL_ID', how='left')\n",
    "\n",
    "# Merge with celltypist_df\n",
    "final_output_celltypist = CTs_with_datasets_df[CTs_with_datasets_df['annotation_method'] == 'celltypist'].merge(\n",
    "    celltypist[['CL_ID', 'Organ_Level']], on='CL_ID', how='left')\n",
    "\n",
    "# Merge with popv_df\n",
    "final_output_popv = CTs_with_datasets_df[CTs_with_datasets_df['annotation_method'] == 'popv'].merge(\n",
    "    popv[['CL_ID', 'Organ_Level']], on='CL_ID', how='left')\n",
    "\n",
    "# Combine all the dataframes\n",
    "final_output_combined = pd.concat([final_output_azimuth, final_output_celltypist, final_output_popv], ignore_index=True)\n",
    "\n",
    "# Define the organ levels for each annotation method\n",
    "azimuth_organs = ['Kidney_L3', 'Lung_v2_finest_level', 'Liver_L2', 'Liver_L1', 'Kidney_L1',  'Kidney_L2', \n",
    "                  'Lung_v2_L1', 'Lung_v2_L2', 'Lung_v2_L3', 'Lung_v2_L4', 'Lung_v2_L5', 'Pancreas_L1']\n",
    "celltypist_organs = ['intestine_L1', 'kidney_L1', 'liver_L1', 'lung_L1', 'pancreas_L1', 'spleen_L1', \n",
    "                     'Adult_Human_Skin_pkl', 'Healthy_Human_Liver_pkl', 'Adult_Human_PancreaticIslet_pkl', \n",
    "                     'Human_Lung_Atlas_pkl']\n",
    "popv_organs = ['large intestine', 'liver', 'lung', 'male reproductive system', 'pancreas', 'prostate gland', \n",
    "               'respiratory system', 'skin', 'small intestine', 'spleen', 'thymus']\n",
    "\n",
    "# Filter the combined dataframe for each annotation method and their corresponding organ levels\n",
    "filtered_azimuth = final_output_combined[(final_output_combined['annotation_method'] == 'azimuth') & \n",
    "                                         (final_output_combined['Organ_Level'].isin(azimuth_organs))]\n",
    "\n",
    "filtered_celltypist = final_output_combined[(final_output_combined['annotation_method'] == 'celltypist') & \n",
    "                                            (final_output_combined['Organ_Level'].isin(celltypist_organs))]\n",
    "\n",
    "filtered_popv = final_output_combined[(final_output_combined['annotation_method'] == 'popv') & \n",
    "                                      (final_output_combined['Organ_Level'].isin(popv_organs))]\n",
    "\n",
    "# Combine the filtered dataframes\n",
    "final_filtered_combined = pd.concat([filtered_azimuth, filtered_celltypist, filtered_popv], ignore_index=True)\n",
    "\n",
    "final_filtered_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ce4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined dataframe to a CSV file\n",
    "output_path = 'output/filtered-CTs-with-datasets-with-organ.csv'\n",
    "final_filtered_combined.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71c047",
   "metadata": {},
   "source": [
    "###  Extract gene information for Cell types in vasculature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3814b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided CT Labels and CT IDs\n",
    "ct_labels_ids = {\n",
    "    \"glomerular capillary endothelial cell\": \"CL:1001005\",\n",
    "    \"efferent arteriole endothelial cell\": \"CL:1001099\",\n",
    "    \"afferent arteriole endothelial cell\": \"CL:1001096\",\n",
    "    \"peritubular capillary endothelial cell\": \"CL:1001033\",\n",
    "    \"vasa recta ascending limb cell\": \"CL:1001131\",\n",
    "    \"vasa recta descending limb cell\": \"CL:1001285\",\n",
    "    \"alveolar capillary type 1 endothelial cell\": \"CL:4028002\",\n",
    "    \"capillary endothelial cell\": \"CL:0002144\",\n",
    "    \"blood vessel smooth muscle cell\": \"CL:0019018\",\n",
    "    \"endothelial cell of artery\": \"CL:1000413\",\n",
    "    \"vein endothelial cell\": \"CL:0002543\",\n",
    "    \"endothelial cell of hepatic sinusoid\": \"CL:1000398\",\n",
    "    \"prostate gland microvascular endothelial cell\": \"CL:2000059\",\n",
    "    \"blood vessel endothelial cell\": \"CL:0000071\",\n",
    "    \"splenic endothelial cell\": \"CL:2000053\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the structure within the \"@graph\" key to process accordingly\n",
    "graph_data = json_data_enriched[\"@graph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping ensembl_ids by cell_id and adding cell_label\n",
    "grouped_matches = {}\n",
    "for item in graph_data:\n",
    "    samples = item.get(\"samples\", [])\n",
    "    for sample in samples:\n",
    "        sections = sample.get(\"sections\", [])\n",
    "        for section in sections:\n",
    "            datasets = section.get(\"datasets\", [])\n",
    "            for dataset in datasets:\n",
    "                summaries = dataset.get(\"summaries\", [])\n",
    "                for summary in summaries:\n",
    "                    sum_details = summary.get(\"summary\", [])\n",
    "                    for sum_detail in sum_details:\n",
    "                        cell_id = sum_detail.get(\"cell_id\")\n",
    "                        gene_expr_list = sum_detail.get(\"gene_expr\", [])\n",
    "                        if cell_id in ct_labels_ids.values():\n",
    "                            if isinstance(gene_expr_list, list):\n",
    "                                for gene_expr in gene_expr_list:\n",
    "                                    if isinstance(gene_expr, dict):\n",
    "                                        ensembl_id = gene_expr.get(\"ensembl_id\")\n",
    "                                        if cell_id not in grouped_matches:\n",
    "                                            grouped_matches[cell_id] = {\"cell_label\": \"\", \"ensembl_ids\": []}\n",
    "                                        grouped_matches[cell_id][\"cell_label\"] = [label for label, id in ct_labels_ids.items() if id == cell_id][0]\n",
    "                                        grouped_matches[cell_id][\"ensembl_ids\"].append(ensembl_id)\n",
    "\n",
    "# Preparing the final dataframe\n",
    "final_matches = []\n",
    "for cell_id, details in grouped_matches.items():\n",
    "    final_matches.append({\n",
    "        \"cell_id\": cell_id,\n",
    "        \"cell_label\": details[\"cell_label\"],\n",
    "        \"ensembl_ids\": \", \".join(details[\"ensembl_ids\"])\n",
    "    })\n",
    "\n",
    "final_matches_df = pd.DataFrame(final_matches)\n",
    "final_matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the final dataframe\n",
    "final_matches_df.to_csv('Biomarker_for_Vasculature_CTs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ff2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matches_df['cell_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd987cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping ensembl_ids by cell_id and organ_id, adding cell_label and mean_gene_expr_value\n",
    "grouped_matches = {}\n",
    "for item in graph_data:\n",
    "    samples = item.get(\"samples\", [])\n",
    "    for sample in samples:\n",
    "        sections = sample.get(\"sections\", [])\n",
    "        for section in sections:\n",
    "            datasets = section.get(\"datasets\", [])\n",
    "            for dataset in datasets:\n",
    "                summaries = dataset.get(\"summaries\", [])               \n",
    "                for summary in summaries:\n",
    "                    annotation_method = summary.get(\"annotation_method\", \"Unknown\")\n",
    "                    sum_details = summary.get(\"summary\", [])\n",
    "                    for sum_detail in sum_details:\n",
    "                        cell_id = sum_detail.get(\"cell_id\")\n",
    "                        gene_expr_list = sum_detail.get(\"gene_expr\", [])\n",
    "                        organ_id = dataset.get(\"organ_id\", \"Unknown\")\n",
    "                        if cell_id in ct_labels_ids.values():\n",
    "                            if isinstance(gene_expr_list, list) and gene_expr_list:\n",
    "                                for gene_expr in gene_expr_list:\n",
    "                                    if isinstance(gene_expr, dict):\n",
    "                                        ensembl_id = gene_expr.get(\"ensembl_id\")\n",
    "                                        mean_expr_value = gene_expr.get(\"mean_gene_expr_value\")\n",
    "                                        key = (cell_id, organ_id, annotation_method)\n",
    "                                        if key not in grouped_matches:\n",
    "                                            grouped_matches[key] = {\"cell_label\": \"\", \"ensembl_ids\": [], \"mean_expr_values\": []}\n",
    "                                        grouped_matches[key][\"cell_label\"] = [label for label, id in ct_labels_ids.items() if id == cell_id][0]\n",
    "                                        grouped_matches[key][\"ensembl_ids\"].append(ensembl_id)\n",
    "                                        grouped_matches[key][\"mean_expr_values\"].append(mean_expr_value)\n",
    "                            else:\n",
    "                                # Handle entries with empty gene_expr lists\n",
    "                                key = (cell_id, organ_id, annotation_method)\n",
    "                                if key not in grouped_matches:\n",
    "                                    grouped_matches[key] = {\"cell_label\": \"\", \"ensembl_ids\": [], \"mean_expr_values\": []}\n",
    "                                grouped_matches[key][\"cell_label\"] = [label for label, id in ct_labels_ids.items() if id == cell_id][0]\n",
    "\n",
    "# Preparing the final dataframe\n",
    "final_matches = []\n",
    "for (cell_id, organ_id, annotation_method), details in grouped_matches.items():\n",
    "    final_matches.append({\n",
    "        \"cell_id\": cell_id,\n",
    "        \"cell_label\": details[\"cell_label\"],\n",
    "        \"organ_id\": organ_id,\n",
    "        \"annotation_method\": annotation_method,\n",
    "        \"ensembl_ids\": \", \".join(details[\"ensembl_ids\"]),\n",
    "        \"mean_expr_values\": \", \".join(map(str, details[\"mean_expr_values\"]))\n",
    "    })\n",
    "\n",
    "final_matches_df = pd.DataFrame(final_matches)\n",
    "\n",
    "# Expanding the dataframe to have each row for each ensembl_id\n",
    "expanded_matches = []\n",
    "for _, row in final_matches_df.iterrows():\n",
    "    cell_id = row[\"cell_id\"]\n",
    "    cell_label = row[\"cell_label\"]\n",
    "    organ_id = row[\"organ_id\"]\n",
    "    annotation_method = row[\"annotation_method\"]\n",
    "    ensembl_ids = row[\"ensembl_ids\"].split(\", \")\n",
    "    mean_expr_values = row[\"mean_expr_values\"].split(\", \")\n",
    "    \n",
    "    for ensembl_id, mean_expr_value in zip(ensembl_ids, mean_expr_values):\n",
    "        try:\n",
    "            mean_expr_value_float = float(mean_expr_value)\n",
    "        except ValueError:\n",
    "            mean_expr_value_float = None  # Handle non-numeric values\n",
    "        expanded_matches.append({\n",
    "            \"cell_id\": cell_id,\n",
    "            \"cell_label\": cell_label,\n",
    "            \"organ_id\": organ_id,\n",
    "            \"annotation_method\": annotation_method,\n",
    "            \"ensembl_id\": ensembl_id,\n",
    "            \"mean_expr_value\": mean_expr_value_float\n",
    "        })\n",
    "\n",
    "expanded_matches_df = pd.DataFrame(expanded_matches)\n",
    "\n",
    "# Displaying the expanded dataframe\n",
    "expanded_matches_df.head()  # Displaying only the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f122e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique organ IDs from the expanded dataframe\n",
    "unique_organ_ids = expanded_matches_df[\"organ_id\"].unique()\n",
    "\n",
    "unique_organ_ids_list = unique_organ_ids.tolist()\n",
    "unique_organ_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_id_to_organ_name = {\n",
    "         'http://purl.obolibrary.org/obo/UBERON_0002113' : 'Kidney',\n",
    "         'http://purl.obolibrary.org/obo/UBERON_0000948' : 'heart',\n",
    "         'http://purl.obolibrary.org/obo/UBERON_0001255': 'urinary bladder',\n",
    "         'http://purl.obolibrary.org/obo/UBERON_0002048' : 'lung',\n",
    "         'http://purl.obolibrary.org/obo/UBERON_0002107' : 'liver'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac496df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column to the dataframe\n",
    "expanded_matches_df['organ_name'] = expanded_matches_df['organ_id'].map(organ_id_to_organ_name)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "expanded_matches_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_matches_df[expanded_matches_df['organ_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and clean up relevant columns from FTU dataframe\n",
    "ftu_cleaned_df = ftu_cell_count[['Organ', 'CL_Label_FTU', 'FTU Label in Uberon']].dropna().drop_duplicates()\n",
    "\n",
    "# Ensure unique mapping by dropping duplicates based on 'CT Label in CL'\n",
    "ftu_unique_df = ftu_cleaned_df.drop_duplicates(subset=['CL_Label_FTU'])\n",
    "\n",
    "# Perform the match and add the new column for FTU name\n",
    "expanded_matches_df['FTU_name'] = expanded_matches_df['cell_label'].map(\n",
    "    ftu_unique_df.set_index('CL_Label_FTU')['FTU Label in Uberon']\n",
    ")\n",
    "\n",
    "# Adding the organ name from FTU data\n",
    "expanded_matches_df['Organ_name_FTU'] = expanded_matches_df['cell_label'].map(\n",
    "    ftu_unique_df.set_index('CL_Label_FTU')['Organ']\n",
    ")\n",
    "\n",
    "# Rearrange columns as per the requirement\n",
    "expanded_matches_df = expanded_matches_df[[\n",
    "    'organ_name', 'Organ_name_FTU','organ_id', 'annotation_method', 'FTU_name', 'cell_id', 'cell_label', 'ensembl_id', 'mean_expr_value'\n",
    "]]\n",
    "\n",
    "# Rename columns for consistency\n",
    "expanded_matches_df.rename(columns={\n",
    "    'organ_name': 'organ_name',\n",
    "    'Organ_name_FTU': 'organ_name_in_FTU'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "expanded_matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc16556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where organ_name is 'heart' or 'urinary bladder'\n",
    "matches_df_filtered = expanded_matches_df[~expanded_matches_df['organ_name'].isin(['heart', 'urinary bladder'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df_filtered.to_csv('output/vasculature/gene_information-for-vasculature-CTs_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df_filtered['FTU_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d4534",
   "metadata": {},
   "source": [
    "#### Generate box plot images for unique cell label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991025b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual box plots for each cell_label\n",
    "unique_cell_labels = matches_df_filtered['cell_label'].unique()\n",
    "\n",
    "for cell_label in unique_cell_labels:\n",
    "    cell_label_data = matches_df_filtered[matches_df_filtered['cell_label'] == cell_label]\n",
    "    \n",
    "    if len(cell_label_data) > 1:  # Ensure there is enough data to plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(data=cell_label_data, y='mean_expr_value', color='skyblue')\n",
    "        \n",
    "        # Customize the box plot\n",
    "        plt.xticks([])\n",
    "        plt.title(f'Box Plot of Mean Expression Values for {cell_label}')\n",
    "        plt.xlabel('Cell Label')\n",
    "        plt.ylabel('Mean Expression Value')\n",
    "        \n",
    "        # Adding additional visual elements\n",
    "        plt.axhline(y=cell_label_data['mean_expr_value'].median(), color='red', linestyle='-', label='Median')\n",
    "        plt.legend()\n",
    "\n",
    "        # Save each plot as an image file\n",
    "        individual_box_plot_file_path = f'output/vasculature/figures/box_plot_mean_expr_value_{cell_label.replace(\" \", \"_\")}.png'\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(individual_box_plot_file_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ef524",
   "metadata": {},
   "source": [
    "#### Generate box plot images for unique cell label per annotation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_annotation_methods = matches_df_filtered['annotation_method'].explode().unique()\n",
    "unique_annotation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_annotation_methods = matches_df_filtered['annotation_method'].explode().unique()\n",
    "\n",
    "for cell_label in unique_cell_labels:\n",
    "    for annotation_method in unique_annotation_methods:\n",
    "        cell_label_data = matches_df_filtered[\n",
    "            (matches_df_filtered['cell_label'] == cell_label) &\n",
    "            (matches_df_filtered['annotation_method'] == annotation_method)\n",
    "        ]\n",
    "        \n",
    "        if len(cell_label_data) > 1:  # Ensure there is enough data to plot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(data=cell_label_data, y='mean_expr_value', color='skyblue')\n",
    "            \n",
    "            # Customize the box plot\n",
    "            plt.xticks([])\n",
    "            plt.title(f'Box Plot of Mean Expression Values for {cell_label} ({annotation_method})')\n",
    "            plt.xlabel('Cell Label')\n",
    "            plt.ylabel('Mean Expression Value')\n",
    "            \n",
    "            # Adding additional visual elements\n",
    "            plt.axhline(y=cell_label_data['mean_expr_value'].median(), color='red', linestyle='-', label='Median')\n",
    "            plt.legend()\n",
    "\n",
    "            # Save each plot as an image file\n",
    "            individual_box_plot_file_path = f'output/vasculature/figures/box_plot_mean_expr_value_{cell_label.replace(\" \", \"_\")}_{annotation_method.replace(\" \", \"_\")}.png'\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(individual_box_plot_file_path)\n",
    "            plt.close()\n",
    "\n",
    "# List of generated plot file paths\n",
    "plot_file_paths = [f'output/vasculature/figures/box_plot_mean_expr_value_{cell_label.replace(\" \", \"_\")}_{annotation_method.replace(\" \", \"_\")}.png'\n",
    "                   for cell_label in unique_cell_labels\n",
    "                   for annotation_method in unique_annotation_methods\n",
    "                   if len(matches_df_filtered[(matches_df_filtered['cell_label'] == cell_label) & (matches_df_filtered['annotation_method'] == annotation_method)]) > 1]\n",
    "\n",
    "plot_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='FTU_name', y='mean_expr_value', hue='annotation_method', data=matches_df_filtered)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Mean Expression Value per Cell Type per FTU Name per Annotation Method')\n",
    "plt.xlabel('FTU Name')\n",
    "plt.ylabel('Mean Expression Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Annotation Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Save the plot to a file\n",
    "output_file_path = 'output/vasculature/mean-expression-box-plot-per-CT-per-FTU-per-AnnMethod.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bab5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='FTU_name', y='mean_expr_value', hue='cell_label', data=matches_df_filtered)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Mean Expression Value per Cell Type per FTU Name')\n",
    "plt.xlabel('FTU Name')\n",
    "plt.ylabel('Mean Expression Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cell Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Save the plot to a file\n",
    "output_file_path = 'output/vasculature/mean_expression_box_plot_per_cell_type.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c0159",
   "metadata": {},
   "source": [
    "### Understand the JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16844622",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'ref_data/atlas-enriched-dataset-graph.jsonld'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract as_label, link, and cell_id from the JSON data\n",
    "def extract_all_entries(json_data):\n",
    "    result = []\n",
    "    for entry in json_data['@graph']:\n",
    "        for sample in entry.get('samples', []):\n",
    "            rui_location = sample.get('rui_location', {})\n",
    "            all_collisions = rui_location.get('all_collisions', [])\n",
    "            for collision in all_collisions:\n",
    "                collisions = collision.get('collisions', [])\n",
    "                for col in collisions:\n",
    "                    as_label = col.get('as_label', 'unknown')\n",
    "                    for section in sample.get('sections', []):\n",
    "                        for dataset in section.get('datasets', []):\n",
    "                            link = dataset.get('link', 'unknown')\n",
    "                            for summary in dataset.get('summaries', []):\n",
    "                                for summary_item in summary.get('summary', []):\n",
    "                                    cell_id = summary_item.get('cell_id', 'unknown')\n",
    "                                    cell_label = summary_item.get('cell_label', 'unknown')\n",
    "                                    new_row = {\n",
    "                                        'as_label': as_label,\n",
    "                                        'link': link,\n",
    "                                        'cell_label': cell_label,\n",
    "                                        'cell_id': cell_id\n",
    "                                    }\n",
    "                                    result.append(new_row)\n",
    "    return result\n",
    "\n",
    "# Extract all entries\n",
    "extracted_data_enriched = extract_all_entries(json_data_enriched)\n",
    "\n",
    "# Convert extracted data to a DataFrame\n",
    "extracted_df_enriched = pd.DataFrame(extracted_data_enriched)\n",
    "\n",
    "# Display the DataFrame's head\n",
    "print(extracted_df_enriched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df.to_csv('output/Dataset-source-cell-enriched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cell IDs from the summary section\n",
    "def extract_cell_ids(data):\n",
    "    cell_ids = []\n",
    "    for item in data['@graph']:\n",
    "        samples = item.get(\"samples\", [])\n",
    "        for sample in samples:\n",
    "            sections = sample.get(\"sections\", [])\n",
    "            for section in sections:\n",
    "                datasets = section.get(\"datasets\", [])\n",
    "                for dataset in datasets:\n",
    "                    summaries = dataset.get(\"summaries\", [])               \n",
    "                    for summary in summaries:\n",
    "                        sum_details = summary.get(\"summary\", [])\n",
    "                        for sum_detail in sum_details:\n",
    "                            cell_id = sum_detail.get(\"cell_id\")\n",
    "                            cell_ids.append(cell_id)\n",
    "    return cell_ids\n",
    "\n",
    "cell_ids = extract_cell_ids(json_data_enriched)\n",
    "print(f\"Cell IDs from the file: {len(cell_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cell_ids_summaries(data):\n",
    "    cell_ids = []\n",
    "    for item in data['@graph']:\n",
    "        summaries = item.get('summary', [])\n",
    "        for summary in summaries:\n",
    "            for detail in summary:\n",
    "                if 'cell_id' in detail:\n",
    "                    cell_ids.append(summary['cell_id'])\n",
    "    return cell_ids\n",
    "\n",
    "cell_ids_summaries = extract_cell_ids_summaries(json_data_summary)\n",
    "print(f\"Cell IDs from the file: {len(cell_ids_summaries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c361dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract aggregated_summaries, cell_source_label, cell_label, and cell_id from the JSON data\n",
    "graph_data = json_data_summary.get('@graph', [])\n",
    "\n",
    "extracted_data_summary = []\n",
    "\n",
    "for item in graph_data:\n",
    "    if 'summary' in item:\n",
    "        for summary in item['summary']:\n",
    "            for summary in summaries:\n",
    "                if 'cell_id' in summary and 'cell_label' in summary:\n",
    "                    for aggregated_summary in aggregated_summaries:\n",
    "                        extracted_entry = {\n",
    "                    'cell_source_label': cell_source_label,\n",
    "                    'aggregated_summary': aggregated_summary,\n",
    "                    'cell_label': summary.get('cell_label'),\n",
    "                    'cell_id': summary.get('cell_id')\n",
    "                }\n",
    "                extracted_data_summary.append(extracted_entry)\n",
    "\n",
    "# Convert extracted data to a DataFrame\n",
    "extracted_df_summary = pd.DataFrame(extracted_data_summary)\n",
    "\n",
    "# Display the DataFrame's head\n",
    "print(extracted_df_summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df_summary.to_csv('output/Dataset-source-cell-summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a47733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
